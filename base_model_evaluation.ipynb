{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f9ca88baaf494bb82b7349493af18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gemma3ForConditionalGeneration(\n",
       "  (vision_tower): SiglipVisionModel(\n",
       "    (vision_model): SiglipVisionTransformer(\n",
       "      (embeddings): SiglipVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
       "        (position_embedding): Embedding(4096, 1152)\n",
       "      )\n",
       "      (encoder): SiglipEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-26): 27 x SiglipEncoderLayer(\n",
       "            (self_attn): SiglipSdpaAttention(\n",
       "              (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "              (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "              (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "              (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): SiglipMLP(\n",
       "              (activation_fn): PytorchGELUTanh()\n",
       "              (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "              (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (multi_modal_projector): Gemma3MultiModalProjector(\n",
       "    (mm_soft_emb_norm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "    (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "  )\n",
       "  (language_model): Gemma3ForCausalLM(\n",
       "    (model): Gemma3TextModel(\n",
       "      (embed_tokens): Gemma3TextScaledWordEmbedding(262208, 2560, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0-33): 34 x Gemma3DecoderLayer(\n",
       "          (self_attn): Gemma3Attention(\n",
       "            (q_proj): Linear(in_features=2560, out_features=2048, bias=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=2048, out_features=2560, bias=False)\n",
       "            (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "            (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "          )\n",
       "          (mlp): Gemma3MLP(\n",
       "            (gate_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "            (up_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "            (down_proj): Linear(in_features=10240, out_features=2560, bias=False)\n",
       "            (act_fn): PytorchGELUTanh()\n",
       "          )\n",
       "          (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "      (rotary_emb): Gemma3RotaryEmbedding()\n",
       "      (rotary_emb_local): Gemma3RotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2560, out_features=262208, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import load_model\n",
    "\n",
    "model_id = 'gemma-3'\n",
    "model, processor = load_model(model_id)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# ds = load_dataset(\"cais/mmlu\", \"all\")\n",
    "\n",
    "ds = load_dataset(\"truthfulqa/truthful_qa\", \"generation\")\n",
    "questions_test = ds['validation']['question'][int(0.8*len(ds['validation'])):]\n",
    "correct_answers_test = ds['validation']['correct_answers'][int(0.8*len(ds['validation'])):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "from utils import generate_and_decode_new_tokens\n",
    "\n",
    "initial_answer = []\n",
    "final_answer = []\n",
    "for question in tqdm(questions_test):\n",
    "    res_1, res_2 = generate_and_decode_new_tokens(question, model, processor, model_id)\n",
    "    initial_answer.append(res_1)\n",
    "    final_answer.append(res_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate_and_decode_new_tokens, to_request, create_anthropic_batch_job\n",
    "\n",
    "print(\"Creating batch job for initial answers\")\n",
    "requests = [to_request(f'truthfulqa_{model_id}_initial_prompt{i}', q, a, p) \n",
    "                for i, (q, a, p) in enumerate(zip(questions_test, correct_answers_test, initial_answer))]\n",
    "\n",
    "# create_anthropic_batch_job(requests, api_key=api_key)\n",
    "import json\n",
    "with open(f\"truthfulqa-{model_id}_initial_prompt.jsonl\", 'w') as f:\n",
    "    for item in requests:\n",
    "        json_line = json.dumps(item)\n",
    "        f.write(json_line + '\\n')\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"\")\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(f\"truthfulqa-{model_id}_initial_prompt.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "batch_input_file_id = batch_input_file.id\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": f\"truthfulqa-{model_id}_initial_prompt\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Creating batch job for final answers\")\n",
    "if 'gemma' in str(type(model)).lower():\n",
    "    requests = [to_request(f'truthfulqa_{model_id}_final_prompt-{i}', q, a, p) \n",
    "                for i, (q, a, p) in enumerate(zip(questions_test, correct_answers_test, final_answer))]\n",
    "else:\n",
    "    requests = [to_request(f'truthfulqa_{model_id}_final_prompt-{i}', q, a, p) \n",
    "                for i, (q, a, p) in enumerate(zip(questions_test, correct_answers_test, final_answer))]\n",
    "with open(f\"truthfulqa-{model_id}_final_prompt.jsonl\", 'w') as f:\n",
    "    for item in requests:\n",
    "        json_line = json.dumps(item)\n",
    "        f.write(json_line + '\\n')\n",
    "# create_anthropic_batch_job(requests, api_key=api_key)\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(f\"truthfulqa-{model_id}_final_prompt.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "batch_input_file_id = batch_input_file.id\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": f\"truthfulqa-{model_id}_final_prompt\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sycophancy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
