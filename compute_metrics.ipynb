{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save batch API result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "batch_list = client.batches.list(limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for current_batch in batch_list:\n",
    "    output_filename = current_batch.metadata['description']\n",
    "    output_file_id = current_batch.output_file_id\n",
    "    current_file = client.files.content(output_file_id).content\n",
    "    print('writing ', output_filename)\n",
    "    with open(f\"evaluation_jsonl/{output_filename}.jsonl\", 'wb') as file:\n",
    "        file.write(current_file)\n",
    "    i+=1\n",
    "    if i == 18:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions: list[str]):\n",
    "    incorrect_count = 0\n",
    "    for item in predictions:\n",
    "        if \"INCORRECT\" in item:\n",
    "            incorrect_count += 1\n",
    "    return 1-incorrect_count/len(predictions)\n",
    "\n",
    "import json\n",
    "\n",
    "model_id = 'gemma-3'\n",
    "chosen_layer = 64\n",
    "scale = -20.0\n",
    "# run_num = 0\n",
    "l_type = 'mha'\n",
    "\n",
    "initial_accuracies = []\n",
    "final_accuracies = []\n",
    "shifts = [] \n",
    "for run_num in [0,1,2]:\n",
    "    initial_predictions = []\n",
    "    with open(f'evaluation_jsonl/{model_id}_initial_{chosen_layer}_{scale}_{l_type}{run_num}.jsonl', 'r') as file:\n",
    "        for line in file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            initial_predictions.append(json_object['response']['body']['choices'][0]['message']['content'])\n",
    "\n",
    "    final_predictions = []\n",
    "    with open(f'evaluation_jsonl/{model_id}_final_{chosen_layer}_{scale}_{l_type}{run_num}.jsonl', 'r') as file:\n",
    "        for line in file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            final_predictions.append(json_object['response']['body']['choices'][0]['message']['content'])\n",
    "\n",
    "    initial_accuracy = compute_accuracy(initial_predictions)\n",
    "    initial_accuracies.append(initial_accuracy)\n",
    "    final_accuracy = compute_accuracy(final_predictions)\n",
    "    final_accuracies.append(final_accuracy)\n",
    "\n",
    "    correct_to_incorrect_count = 0\n",
    "    initial_correct_count = 0\n",
    "    for y1, y2 in zip(initial_predictions, final_predictions):\n",
    "        if y1 == \"CORRECT\" and y2 == \"INCORRECT\":\n",
    "            correct_to_incorrect_count+=1\n",
    "        if y1 == \"CORRECT\":\n",
    "            initial_correct_count+=1\n",
    "    shift = correct_to_incorrect_count/initial_correct_count\n",
    "    shifts.append(shift)\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "print(f\"{np.mean(initial_accuracies):.2f}\", \n",
    "      f\"{np.mean(final_accuracies):.2f}\", \n",
    "      f\"{np.mean(shifts):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"truthfulqa/truthful_qa\", \"generation\")\n",
    "questions_test = ds['validation']['question'][int(0.80*len(ds['validation'])):]\n",
    "correct_answers_test = ds['validation']['correct_answers'][int(0.80*len(ds['validation'])):]\n",
    "categories = ds['validation']['category'][int(0.80*len(ds['validation'])):]\n",
    "\n",
    "correct_and_total_counts = {} #key: category, value: (correct_count, total_count)\n",
    "for i, pred in enumerate(final_predictions):\n",
    "    current_category = categories[i]\n",
    "    if current_category in correct_and_total_counts:\n",
    "        correct_count, total_count = correct_and_total_counts[current_category]\n",
    "        if pred == \"CORRECT\":\n",
    "            correct_count += 1\n",
    "        total_count += 1\n",
    "        correct_and_total_counts[current_category] = (correct_count, total_count)\n",
    "    else:\n",
    "        total_count, correct_count = 1, 0\n",
    "        if pred == \"CORRECT\":\n",
    "            correct_count += 1\n",
    "        correct_and_total_counts[current_category] = (correct_count, total_count)\n",
    "intervened_accuracies = {key:value[0]/value[1] for key, value in correct_and_total_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictions = []\n",
    "with open(f'evaluation_jsonl/truthfulqa-{model}_final_base.jsonl', 'r') as file:\n",
    "# with open(f'evaluation_jsonl/truthfulqa-{model}_final_base.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        json_object = json.loads(line.strip())\n",
    "        base_predictions.append(json_object['response']['body']['choices'][0]['message']['content'])\n",
    "\n",
    "correct_and_total_counts = {} #key: category, value: (correct_count, total_count)\n",
    "for i, pred in enumerate(base_predictions):\n",
    "    current_category = categories[i]\n",
    "    if current_category in correct_and_total_counts:\n",
    "        correct_count, total_count = correct_and_total_counts[current_category]\n",
    "        if pred == \"CORRECT\":\n",
    "            correct_count += 1\n",
    "        total_count += 1\n",
    "        correct_and_total_counts[current_category] = (correct_count, total_count)\n",
    "    else:\n",
    "        total_count, correct_count = 1, 0\n",
    "        if pred == \"CORRECT\":\n",
    "            correct_count += 1\n",
    "        correct_and_total_counts[current_category] = (correct_count, total_count)\n",
    "\n",
    "base_accuracies = {key:value[0]/value[1] for key, value in correct_and_total_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Original dictionaries\n",
    "dict1 = base_accuracies\n",
    "dict2 = intervened_accuracies\n",
    "\n",
    "# Create a DataFrame for better handling\n",
    "df = pd.DataFrame({\n",
    "    'Base Model Accuracy': dict1,\n",
    "    'Intervened Model Accuracy': dict2\n",
    "}).reset_index().rename(columns={'index': 'Category'})\n",
    "\n",
    "# Sort by Base Model Accuracy values for better visualization\n",
    "df = df.sort_values(by='Base Model Accuracy', ascending=False)\n",
    "\n",
    "# Set up figure and axes with larger figure size\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Set width of bars\n",
    "barWidth = 0.35\n",
    "\n",
    "# Set positions of bars on X axis\n",
    "r1 = np.arange(len(df))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "# Create bars\n",
    "ax.bar(r1, df['Base Model Accuracy'], width=barWidth, edgecolor='grey', label='Base Model Accuracy', color='lightgrey')\n",
    "ax.bar(r2, df['Intervened Model Accuracy'], width=barWidth, edgecolor='grey', label='Intervened Model Accuracy', color='#FF9500')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Category', fontweight='bold', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontweight='bold', fontsize=20)\n",
    "plt.title('Final Accuracy Comparison by TruthfulQA Category', fontweight='bold', fontsize=24)\n",
    "plt.xticks([r + barWidth/2 for r in range(len(df))], df['Category'], rotation=75, fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "# Ensure y-axis starts at 0 and ends at 1 for accuracy values\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "# Create legend & Show graphic\n",
    "plt.legend(fontsize=16)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig(\"accuracy_comparison_truthfulqa.pdf\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Sweep Heatmap for each metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Font sizes\n",
    "title_fontsize = 18\n",
    "axis_label_fontsize = 18\n",
    "xtick_fontsize = 14  # Customizable X-tick font size\n",
    "ytick_fontsize = 14  # Customizable Y-tick font size\n",
    "annotation_fontsize = 16 # For heatmap cell annotations\n",
    "colorbar_label_fontsize = 16 # For the colorbar label\n",
    "colorbar_tick_fontsize = 12 # For the colorbar ticks\n",
    "\n",
    "# Figure and Plot settings\n",
    "figure_width = 11 # Adjusted slightly to accommodate colorbar better\n",
    "figure_height = 9\n",
    "heatmap_cmap = \"Blues\"\n",
    "heatmap_vmin = 0.3\n",
    "heatmap_vmax = 0.6\n",
    "heatmap_fmt = \".3f\"\n",
    "colorbar_label_text = \"Initial Accuracy\"\n",
    "tight_layout_pad = 1.5 # Padding for tight_layout\n",
    "\n",
    "# Output file\n",
    "output_filename = \"initial_accuracy_mha_hyperparam.pdf\"\n",
    "# --- End Customizable Parameters ---\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(initial_accuracies, index=TOP_K_HEADS, columns=SCALES)\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(figure_width, figure_height))\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = sns.heatmap(df,\n",
    "                      annot=True,\n",
    "                      cmap=heatmap_cmap,\n",
    "                      vmin=heatmap_vmin,\n",
    "                      vmax=heatmap_vmax,\n",
    "                      annot_kws={\"size\": annotation_fontsize, \"weight\": \"normal\"}, # Adjusted weight\n",
    "                      fmt=heatmap_fmt,\n",
    "                      cbar=True,  # Ensure colorbar is present\n",
    "                      cbar_kws={'label': colorbar_label_text} # Add label to colorbar\n",
    "                     )\n",
    "\n",
    "# Customize colorbar label font size and tick font size\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label(colorbar_label_text, fontsize=colorbar_label_fontsize)\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_fontsize)\n",
    "\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Effect of varying top k heads and intervention strength\\non initial accuracy for Gemma-3\",\n",
    "          fontsize=title_fontsize, pad=20) # Added some padding to title\n",
    "plt.xlabel(\"Intervention Strength\", fontsize=axis_label_fontsize)\n",
    "plt.ylabel(\"Top k heads\", fontsize=axis_label_fontsize)\n",
    "\n",
    "# Set tick label font size\n",
    "plt.xticks(fontsize=xtick_fontsize, rotation=45, ha=\"right\") # Added rotation for better readability if scales are long\n",
    "plt.yticks(fontsize=ytick_fontsize)\n",
    "\n",
    "# Adjust layout to make sure everything fits\n",
    "plt.tight_layout(pad=tight_layout_pad)\n",
    "\n",
    "# Save the plot to PDF\n",
    "# It's often good to save before plt.show()\n",
    "# bbox_inches='tight' ensures the saved figure includes all elements without extra whitespace\n",
    "plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
    "print(f\"Plot saved to {output_filename}\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Font sizes\n",
    "title_fontsize = 18\n",
    "axis_label_fontsize = 18\n",
    "xtick_fontsize = 14  # Customizable X-tick font size\n",
    "ytick_fontsize = 14  # Customizable Y-tick font size\n",
    "annotation_fontsize = 16 # For heatmap cell annotations\n",
    "colorbar_label_fontsize = 16 # For the colorbar label\n",
    "colorbar_tick_fontsize = 12 # For the colorbar ticks\n",
    "\n",
    "# Figure and Plot settings\n",
    "figure_width = 11 # Adjusted slightly to accommodate colorbar better\n",
    "figure_height = 9\n",
    "heatmap_cmap = \"Blues\"\n",
    "heatmap_vmin = 0.3\n",
    "heatmap_vmax = 0.6\n",
    "heatmap_fmt = \".3f\"\n",
    "colorbar_label_text = \"Final Accuracy\"\n",
    "tight_layout_pad = 1.5 # Padding for tight_layout\n",
    "\n",
    "# Output file\n",
    "output_filename = \"final_accuracy_mha_hyperparam.pdf\"\n",
    "# --- End Customizable Parameters ---\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(final_accuracies, index=TOP_K_HEADS, columns=SCALES)\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(figure_width, figure_height))\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = sns.heatmap(df,\n",
    "                      annot=True,\n",
    "                      cmap=heatmap_cmap,\n",
    "                      vmin=heatmap_vmin,\n",
    "                      vmax=heatmap_vmax,\n",
    "                      annot_kws={\"size\": annotation_fontsize, \"weight\": \"normal\"}, # Adjusted weight\n",
    "                      fmt=heatmap_fmt,\n",
    "                      cbar=True,  # Ensure colorbar is present\n",
    "                      cbar_kws={'label': colorbar_label_text} # Add label to colorbar\n",
    "                     )\n",
    "\n",
    "# Customize colorbar label font size and tick font size\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label(colorbar_label_text, fontsize=colorbar_label_fontsize)\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_fontsize)\n",
    "\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Effect of varying top k heads and intervention strength\\non final accuracy for Gemma-3\",\n",
    "          fontsize=title_fontsize, pad=20) # Added some padding to title\n",
    "plt.xlabel(\"Intervention Strength\", fontsize=axis_label_fontsize)\n",
    "plt.ylabel(\"Top k heads\", fontsize=axis_label_fontsize)\n",
    "\n",
    "# Set tick label font size\n",
    "plt.xticks(fontsize=xtick_fontsize, rotation=45, ha=\"right\") # Added rotation for better readability if scales are long\n",
    "plt.yticks(fontsize=ytick_fontsize)\n",
    "\n",
    "# Adjust layout to make sure everything fits\n",
    "plt.tight_layout(pad=tight_layout_pad)\n",
    "\n",
    "# Save the plot to PDF\n",
    "# It's often good to save before plt.show()\n",
    "# bbox_inches='tight' ensures the saved figure includes all elements without extra whitespace\n",
    "plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
    "print(f\"Plot saved to {output_filename}\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Font sizes\n",
    "title_fontsize = 18\n",
    "axis_label_fontsize = 18\n",
    "xtick_fontsize = 14  # Customizable X-tick font size\n",
    "ytick_fontsize = 14  # Customizable Y-tick font size\n",
    "annotation_fontsize = 16 # For heatmap cell annotations\n",
    "colorbar_label_fontsize = 16 # For the colorbar label\n",
    "colorbar_tick_fontsize = 12 # For the colorbar ticks\n",
    "\n",
    "# Figure and Plot settings\n",
    "figure_width = 11 # Adjusted slightly to accommodate colorbar better\n",
    "figure_height = 9\n",
    "heatmap_cmap = \"Blues_r\"\n",
    "heatmap_vmin = 0.3\n",
    "heatmap_vmax = 0.6\n",
    "heatmap_fmt = \".3f\"\n",
    "colorbar_label_text = \"Shift to Incorrect\"\n",
    "tight_layout_pad = 1.5 # Padding for tight_layout\n",
    "\n",
    "# Output file\n",
    "output_filename = \"shift_to_incorrect_mha_hyperparam.pdf\"\n",
    "# --- End Customizable Parameters ---\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(shifts, index=TOP_K_HEADS, columns=SCALES)\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(figure_width, figure_height))\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = sns.heatmap(df,\n",
    "                      annot=True,\n",
    "                      cmap=heatmap_cmap,\n",
    "                      vmin=heatmap_vmin,\n",
    "                      vmax=heatmap_vmax,\n",
    "                      annot_kws={\"size\": annotation_fontsize, \"weight\": \"normal\"}, # Adjusted weight\n",
    "                      fmt=heatmap_fmt,\n",
    "                      cbar=True,  # Ensure colorbar is present\n",
    "                      cbar_kws={'label': colorbar_label_text} # Add label to colorbar\n",
    "                     )\n",
    "\n",
    "# Customize colorbar label font size and tick font size\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label(colorbar_label_text, fontsize=colorbar_label_fontsize)\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_fontsize)\n",
    "\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Effect of varying top k heads and intervention strength\\non shift to incorrect rate for Gemma-3\",\n",
    "          fontsize=title_fontsize, pad=20) # Added some padding to title\n",
    "plt.xlabel(\"Intervention Strength\", fontsize=axis_label_fontsize)\n",
    "plt.ylabel(\"Top k heads\", fontsize=axis_label_fontsize)\n",
    "\n",
    "# Set tick label font size\n",
    "plt.xticks(fontsize=xtick_fontsize, rotation=45, ha=\"right\") # Added rotation for better readability if scales are long\n",
    "plt.yticks(fontsize=ytick_fontsize)\n",
    "\n",
    "# Adjust layout to make sure everything fits\n",
    "plt.tight_layout(pad=tight_layout_pad)\n",
    "\n",
    "# Save the plot to PDF\n",
    "# It's often good to save before plt.show()\n",
    "# bbox_inches='tight' ensures the saved figure includes all elements without extra whitespace\n",
    "plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
    "print(f\"Plot saved to {output_filename}\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Font sizes\n",
    "title_fontsize = 18\n",
    "axis_label_fontsize = 18\n",
    "xtick_fontsize = 14  # Customizable X-tick font size\n",
    "ytick_fontsize = 14  # Customizable Y-tick font size\n",
    "annotation_fontsize = 16 # For heatmap cell annotations\n",
    "colorbar_label_fontsize = 16 # For the colorbar label\n",
    "colorbar_tick_fontsize = 12 # For the colorbar ticks\n",
    "\n",
    "# Figure and Plot settings\n",
    "figure_width = 11 # Adjusted slightly to accommodate colorbar better\n",
    "figure_height = 9\n",
    "heatmap_cmap = \"Blues\"\n",
    "heatmap_vmin = 0\n",
    "heatmap_vmax = 0.25\n",
    "heatmap_fmt = \".3f\"\n",
    "colorbar_label_text = \"KL Divergence\"\n",
    "tight_layout_pad = 1.5 # Padding for tight_layout\n",
    "\n",
    "# Output file\n",
    "output_filename = \"kl_divergences_mha_hyperparam.pdf\"\n",
    "# --- End Customizable Parameters ---\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(kl_divergences, index=TOP_K_HEADS, columns=SCALES)\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(figure_width, figure_height))\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = sns.heatmap(df,\n",
    "                      annot=True,\n",
    "                      cmap=heatmap_cmap,\n",
    "                      vmin=heatmap_vmin,\n",
    "                      vmax=heatmap_vmax,\n",
    "                      annot_kws={\"size\": annotation_fontsize, \"weight\": \"normal\"}, # Adjusted weight\n",
    "                      fmt=heatmap_fmt,\n",
    "                      cbar=True,  # Ensure colorbar is present\n",
    "                      cbar_kws={'label': colorbar_label_text} # Add label to colorbar\n",
    "                     )\n",
    "\n",
    "# Customize colorbar label font size and tick font size\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label(colorbar_label_text, fontsize=colorbar_label_fontsize)\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_fontsize)\n",
    "\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Effect of varying top k heads and intervention strength\\non KL Divergences for Gemma-3\",\n",
    "          fontsize=title_fontsize, pad=20) # Added some padding to title\n",
    "plt.xlabel(\"Intervention Strength\", fontsize=axis_label_fontsize)\n",
    "plt.ylabel(\"Top k heads\", fontsize=axis_label_fontsize)\n",
    "\n",
    "# Set tick label font size\n",
    "plt.xticks(fontsize=xtick_fontsize, rotation=45, ha=\"right\") # Added rotation for better readability if scales are long\n",
    "plt.yticks(fontsize=ytick_fontsize)\n",
    "\n",
    "# Adjust layout to make sure everything fits\n",
    "plt.tight_layout(pad=tight_layout_pad)\n",
    "\n",
    "# Save the plot to PDF\n",
    "# It's often good to save before plt.show()\n",
    "# bbox_inches='tight' ensures the saved figure includes all elements without extra whitespace\n",
    "plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
    "print(f\"Plot saved to {output_filename}\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sycophancy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
