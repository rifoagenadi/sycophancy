{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MHA per Head Probe Accuracies Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os # For path manipulation, if needed\n",
    "import matplotlib.colors as mcolors # Moved import to the top\n",
    "\n",
    "def plot_mha_heatmap(accuracies, model_id, num_layers, num_heads,\n",
    "                     sort_layer_accuracies=None, font_sizes=None,\n",
    "                     output_pdf_path=None, color_scheme='importance'):\n",
    "    \"\"\"\n",
    "    Plots a heatmap for MHA accuracies and shows it.\n",
    "    Optionally saves the plot to a PDF file if `output_pdf_path` is provided.\n",
    "\n",
    "    Accuracies can be sorted within each layer if `sort_layer_accuracies`\n",
    "    is set to 'ascending' or 'descending'. Otherwise, original head order is used.\n",
    "    Font sizes and styles for various plot elements can be configured via the `font_sizes` dict.\n",
    "    Color schemes can be chosen to better represent the concept of importance.\n",
    "\n",
    "    Args:\n",
    "        accuracies (dict): Dictionary with keys like 'layer_head' (e.g., '0_1')\n",
    "                           and values as accuracy percentages.\n",
    "        model_id (str): Identifier for the model, used in the plot title.\n",
    "        num_layers (int): Total number of layers in the model.\n",
    "        num_heads (int): Total number of attention heads per layer.\n",
    "        sort_layer_accuracies (str, optional): If 'ascending' or 'descending',\n",
    "                                               sorts accuracies within each layer.\n",
    "                                               Defaults to None (original head order).\n",
    "        font_sizes (dict, optional): Dictionary to override default font sizes and styles for\n",
    "                                     'title', 'xlabel', 'ylabel', 'xticks', 'yticks',\n",
    "                                     'colorbar_label', 'colorbar_ticks',\n",
    "                                     'xtick_rotation', 'xtick_interval'.\n",
    "                                     Defaults to None (uses default_font_config).\n",
    "        output_pdf_path (str, optional): If provided, the path (including filename)\n",
    "                                         where the plot will be saved as a PDF.\n",
    "                                         Example: 'my_plot.pdf'. Defaults to None.\n",
    "        color_scheme (str, optional): Color scheme to use. Options include:\n",
    "                                     'importance' (default): gray to red\n",
    "                                     'warm': gray to orange/red\n",
    "                                     'cool': gray to blue\n",
    "                                     'diverging': blue through gray to red\n",
    "                                     'plasma': gray to plasma colors\n",
    "                                     'inferno': gray to inferno colors\n",
    "                                     'clusters'/'importance_clusters': 3-level importance\n",
    "                                     'discrete_clusters': 3-level importance (sharp boundaries)\n",
    "    \"\"\"\n",
    "    print(\"Generating MHA heatmap...\")\n",
    "\n",
    "    # --- Font size and style configuration ---\n",
    "    default_font_config = {\n",
    "        'title': 18,\n",
    "        'xlabel': 16,\n",
    "        'ylabel': 16,\n",
    "        'xticks': 14,         # Font size for x-tick labels\n",
    "        'yticks': 14,         # Font size for y-tick labels\n",
    "        'colorbar_label': 16,\n",
    "        'colorbar_ticks': 14,\n",
    "        'xtick_rotation': 45, # Default rotation for x-tick labels\n",
    "        'xtick_interval': None # Default interval for x-ticks (None means adaptive)\n",
    "    }\n",
    "    if font_sizes is None:\n",
    "        current_font_sizes = default_font_config\n",
    "    else:\n",
    "        current_font_sizes = default_font_config.copy()\n",
    "        current_font_sizes.update(font_sizes)\n",
    "\n",
    "    # --- Data processing ---\n",
    "    rows = []\n",
    "    for key, value in accuracies.items():\n",
    "        try:\n",
    "            layer, head = map(int, key.split('_'))\n",
    "            rows.append({'layer': layer, 'head': head, 'accuracy': value})\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Could not parse key '{key}' as layer_head. Skipping.\")\n",
    "            continue\n",
    "\n",
    "    if not rows:\n",
    "        print(\"No valid data to plot for MHA heatmap (parsed data is empty).\")\n",
    "        # Consider creating an empty plot or returning if truly no data\n",
    "        # For now, it will proceed and likely show an empty plot with labels.\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    accuracy_matrix_original_order = np.full((num_layers, num_heads), np.nan)\n",
    "\n",
    "    if not df.empty:\n",
    "        for index, row in df.iterrows():\n",
    "            if 0 <= row['layer'] < num_layers and 0 <= row['head'] < num_heads:\n",
    "                accuracy_matrix_original_order[int(row['layer']), int(row['head'])] = row['accuracy']\n",
    "            else:\n",
    "                print(f\"Warning: Data point layer {row['layer']}, head {row['head']} out of bounds. Skipping.\")\n",
    "\n",
    "    display_matrix = np.copy(accuracy_matrix_original_order)\n",
    "    xlabel_text = 'Head Index'\n",
    "\n",
    "    if sort_layer_accuracies in ['ascending', 'descending']:\n",
    "        print(f\"Sorting accuracies within each layer ({sort_layer_accuracies})...\")\n",
    "        temp_sorted_matrix = np.full((num_layers, num_heads), np.nan)\n",
    "        for i in range(num_layers):\n",
    "            layer_row = accuracy_matrix_original_order[i, :]\n",
    "            nan_mask = np.isnan(layer_row)\n",
    "            valid_values = layer_row[~nan_mask]\n",
    "            if valid_values.size > 0:\n",
    "                if sort_layer_accuracies == 'ascending':\n",
    "                    sorted_valid_values = np.sort(valid_values)\n",
    "                else: # descending\n",
    "                    sorted_valid_values = np.sort(valid_values)[::-1]\n",
    "                temp_sorted_matrix[i, :len(sorted_valid_values)] = sorted_valid_values\n",
    "        display_matrix = temp_sorted_matrix\n",
    "        if sort_layer_accuracies == 'ascending':\n",
    "            xlabel_text = 'Head Rank (sorted ascending by accuracy within layer)'\n",
    "        elif sort_layer_accuracies == 'descending':\n",
    "            xlabel_text = 'Head Rank (sorted descending by accuracy within layer)'\n",
    "    elif sort_layer_accuracies is not None:\n",
    "        print(f\"Warning: Invalid value '{sort_layer_accuracies}' for sort_layer_accuracies. No sorting.\")\n",
    "\n",
    "    # --- Color scheme selection ---\n",
    "    norm = None # Initialize norm for discrete_clusters\n",
    "    n_bins_cmap = 256 # Default number of bins for continuous colormaps\n",
    "\n",
    "    if color_scheme == 'clusters' or color_scheme == 'importance_clusters':\n",
    "        # Designed for data values expected roughly in 40-100 range\n",
    "        # Nodes are normalized, so imshow's vmin/vmax will map to these.\n",
    "        nodes = [0.0, 0.75, 0.8, 1.0] # Relative positions for 40, 60, 85, 100\n",
    "        cluster_map_colors = ['#f0f0f0', '#b0b0b0', '#FF9500', '#ff0000']\n",
    "        # Ensure nodes are monotonically increasing and within [0,1]\n",
    "        valid_nodes = []\n",
    "        valid_colors = []\n",
    "        last_node = -1.0\n",
    "        for node, color in zip(nodes, cluster_map_colors):\n",
    "            if 0.0 <= node <= 1.0 and node > last_node:\n",
    "                valid_nodes.append(node)\n",
    "                valid_colors.append(color)\n",
    "                last_node = node\n",
    "            else:\n",
    "                print(f\"Warning: Invalid node {node} for 'clusters' colormap. Skipping.\")\n",
    "        if not valid_nodes or valid_nodes[0] != 0.0: # Ensure first node is 0\n",
    "            valid_nodes.insert(0, 0.0)\n",
    "            valid_colors.insert(0, cluster_map_colors[0]) # Use first color\n",
    "        if valid_nodes[-1] != 1.0: # Ensure last node is 1\n",
    "             valid_nodes.append(1.0)\n",
    "             valid_colors.append(cluster_map_colors[-1]) # Use last color\n",
    "\n",
    "        cmap = mcolors.LinearSegmentedColormap.from_list(\n",
    "            'importance_clusters', list(zip(valid_nodes, valid_colors)), N=n_bins_cmap\n",
    "        )\n",
    "    elif color_scheme == 'importance' or color_scheme == 'warm':\n",
    "        colors = ['lightgray', 'gray', '#ff9999', '#ff6666', '#ff3333', '#ff0000', '#cc0000']\n",
    "        cmap = mcolors.LinearSegmentedColormap.from_list('gray_red', colors, N=n_bins_cmap)\n",
    "    elif color_scheme == 'cool':\n",
    "        colors = ['lightgray', 'gray', '#9999ff', '#6666ff', '#3333ff', '#0000ff', '#0000cc']\n",
    "        cmap = mcolors.LinearSegmentedColormap.from_list('gray_blue', colors, N=n_bins_cmap)\n",
    "    elif color_scheme == 'diverging':\n",
    "        colors = ['#0000cc', '#6666ff', 'lightgray', '#ff6666', '#cc0000'] # Simplified\n",
    "        cmap = mcolors.LinearSegmentedColormap.from_list('blue_gray_red', colors, N=n_bins_cmap)\n",
    "    elif color_scheme == 'plasma':\n",
    "        cmap_base = plt.cm.get_cmap('plasma').copy()\n",
    "        cmap = mcolors.LinearSegmentedColormap.from_list(\n",
    "            \"custom_plasma\", ['lightgray'] + [cmap_base(i) for i in np.linspace(0.1, 1, n_bins_cmap-1)], N=n_bins_cmap\n",
    "        ) # Prepend lightgray for values near/below vmin\n",
    "    elif color_scheme == 'inferno':\n",
    "        cmap_base = plt.cm.get_cmap('inferno').copy()\n",
    "        cmap = mcolors.LinearSegmentedColormap.from_list(\n",
    "            \"custom_inferno\", ['lightgray'] + [cmap_base(i) for i in np.linspace(0.1, 1, n_bins_cmap-1)], N=n_bins_cmap\n",
    "        )\n",
    "    elif color_scheme == 'discrete_clusters':\n",
    "        from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "        cluster_colors = ['#f0f0f0', '#b0c4de', '#ff4500'] # Irrelevant, Neutral, Important\n",
    "        bounds = [40, 60, 85, 100] # Data values defining boundaries\n",
    "        cmap = ListedColormap(cluster_colors)\n",
    "        norm = BoundaryNorm(bounds, cmap.N) # norm maps data values to colormap indices\n",
    "    else:\n",
    "        colors = ['lightgray', 'gray', '#ff9999', '#ff6666', '#ff3333', '#ff0000', '#cc0000']\n",
    "        cmap = mcolors.LinearSegmentedColormap.from_list('default_gray_red', colors, N=n_bins_cmap)\n",
    "        print(f\"Warning: Unrecognized color scheme '{color_scheme}'. Using default 'importance' scheme.\")\n",
    "\n",
    "    cmap.set_bad('white')  # Missing values (NaNs) shown in white\n",
    "\n",
    "    # --- Plotting ---\n",
    "    fig, ax = plt.subplots(figsize=(7, 7)) # User's preferred figsize\n",
    "\n",
    "    max_acc_from_df = df['accuracy'].max() if not df.empty and 'accuracy' in df.columns and df['accuracy'].notna().any() else np.nan\n",
    "    vmin_val = 40\n",
    "    # Ensure vmax_val is sensible\n",
    "    vmax_val = max(vmin_val + 1, 90, max_acc_from_df if pd.notna(max_acc_from_df) else vmin_val + 10)\n",
    "\n",
    "\n",
    "    if display_matrix.shape[0] == 0 or display_matrix.shape[1] == 0 or np.all(np.isnan(display_matrix)):\n",
    "        print(\"Warning: Display matrix is empty or all NaNs. Cannot create heatmap image.\")\n",
    "        ax.text(0.5, 0.5, \"No data to display\", horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "        # Set labels and title even for an empty plot for consistency\n",
    "    else:\n",
    "        if color_scheme == 'discrete_clusters' and norm:\n",
    "            heatmap = ax.imshow(display_matrix, cmap=cmap, aspect='auto', norm=norm) # norm handles vmin/vmax implicitly\n",
    "            # For discrete, colorbar ticks should correspond to the segments\n",
    "            cbar_ticks = [(bounds[i] + bounds[i+1]) / 2 for i in range(len(bounds)-1)]\n",
    "            cbar = plt.colorbar(heatmap, ax=ax, boundaries=bounds, ticks=cbar_ticks)\n",
    "            # Optionally, set custom tick labels for discrete clusters:\n",
    "            # cbar.ax.set_yticklabels([f'{bounds[i]}-{bounds[i+1]}%' for i in range(len(bounds)-1)])\n",
    "        else: # For continuous colormaps\n",
    "            heatmap = ax.imshow(display_matrix, cmap=cmap, aspect='auto', vmin=vmin_val, vmax=vmax_val)\n",
    "            cbar = plt.colorbar(heatmap, ax=ax)\n",
    "\n",
    "        cbar.set_label('Accuracy (%)', fontsize=current_font_sizes['colorbar_label'])\n",
    "        cbar.ax.tick_params(labelsize=current_font_sizes['colorbar_ticks'])\n",
    "\n",
    "    ax.set_xlabel(xlabel_text, fontsize=current_font_sizes['xlabel'])\n",
    "    ax.set_ylabel('Layer Index', fontsize=current_font_sizes['ylabel'])\n",
    "    ax.set_title(f'Probe Accuracy Heatmap by Layer and Head (MHA)\\n{model_id}', fontsize=current_font_sizes['title'])\n",
    "\n",
    "    # --- X-axis ticks ---\n",
    "    if num_heads > 0:\n",
    "        user_xtick_interval = current_font_sizes.get('xtick_interval')\n",
    "        step = 1 # Default step\n",
    "\n",
    "        if user_xtick_interval and isinstance(user_xtick_interval, int) and user_xtick_interval > 0:\n",
    "            step = user_xtick_interval\n",
    "        else: # Default adaptive step calculation\n",
    "            if num_heads <= 16: # If 16 or fewer heads, show every head\n",
    "                step = 1\n",
    "            else: # More than 16 heads, calculate step to show around 16 ticks\n",
    "                target_display_ticks = 16.0\n",
    "                step = max(1, int(round(num_heads / target_display_ticks)))\n",
    "        \n",
    "        ticks_to_show = np.arange(0, num_heads, step)\n",
    "        if len(ticks_to_show) == 0 : # Ensure at least one tick if num_heads > 0\n",
    "             ticks_to_show = np.array([0]) if num_heads == 1 else np.array([])\n",
    "\n",
    "\n",
    "        ax.set_xticks(ticks_to_show)\n",
    "        ax.tick_params(axis='x', labelsize=current_font_sizes['xticks'], rotation=current_font_sizes['xtick_rotation'])\n",
    "    else:\n",
    "        ax.set_xticks([])\n",
    "\n",
    "    # --- Y-axis ticks ---\n",
    "    if num_layers > 0:\n",
    "        # Adaptive y-ticks, similar to default x-tick logic but for layers\n",
    "        if num_layers <= 12:\n",
    "            y_step = 1\n",
    "        elif num_layers <= 24:\n",
    "            y_step = 2\n",
    "        else:\n",
    "            y_step = max(1, num_layers // 12) # Aim for ~12 y-ticks\n",
    "        ax.set_yticks(np.arange(0, num_layers, y_step))\n",
    "        ax.tick_params(axis='y', labelsize=current_font_sizes['yticks'])\n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_pdf_path:\n",
    "        try:\n",
    "            output_dir = os.path.dirname(output_pdf_path)\n",
    "            if output_dir and not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "                print(f\"Created directory: {output_dir}\")\n",
    "            plt.savefig(output_pdf_path, format='pdf', bbox_inches='tight', dpi=300)\n",
    "            print(f\"Plot saved to {output_pdf_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving plot to {output_pdf_path}: {e}\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    print(\"MHA heatmap generation complete.\")\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "#     sample_accuracies_large = {}\n",
    "#     np.random.seed(42)\n",
    "#     num_l_large = 24\n",
    "#     num_h_large = 64 # Many heads to test tick skipping\n",
    "#     for layer in range(num_l_large):\n",
    "#         for head in range(num_h_large):\n",
    "#             accuracy = 40 + np.random.beta(2 + layer/4, 5 - layer/10) * 55\n",
    "#             sample_accuracies_large[f\"{layer}_{head}\"] = accuracy\n",
    "\n",
    "#     print(\"\\n--- Example with many heads (default tick interval) ---\")\n",
    "    # plot_mha_heatmap(\n",
    "    #     accuracies=sample_accuracies_large,\n",
    "    #     model_id=\"Large Model (Default X-Ticks)\",\n",
    "    #     num_layers=num_l_large,\n",
    "    #     num_heads=num_h_large,\n",
    "    #     color_scheme='inferno',\n",
    "    #     font_sizes={'xtick_rotation': 60, 'xticks': 8} # Smaller font for many rotated ticks\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "model_id = 'gemma-3'\n",
    "accuracies = pkl.load(open(f'linear_probe/trained_probe/gemma-3-4b-it/accuracies_dict_mha.pkl', 'rb'))\n",
    "# accuracies = pkl.load(open(f'linear_probe/trained_probe/Qwen3-4B-Instruct-2507/accuracies_dict_mha.pkl', 'rb'))\n",
    "# accuracies = pkl.load(open(f'linear_probe/trained_probe/Llama-3.2-3B-Instruct/accuracies_dict_mha.pkl', 'rb'))\n",
    "if 'gemma' in model_id:\n",
    "    NUM_HEADS = 8\n",
    "    NUM_LAYERS = 34\n",
    "elif 'qwen-3' in model_id:\n",
    "    NUM_HEADS = 36\n",
    "    NUM_LAYERS = 32\n",
    "else: # Assuming Llama-like structure otherwise\n",
    "    NUM_LAYERS = 28\n",
    "    NUM_HEADS = 24\n",
    "\n",
    "# plot_mha_heatmap(accuracies, model_id, NUM_LAYERS, NUM_HEADS, sort_layer_accuracies=None, output_pdf_path=f'{model_id}_mha_heatmap.pdf', color_scheme=\"clusters\")\n",
    "\n",
    "plot_mha_heatmap(\n",
    "    accuracies=accuracies,\n",
    "    model_id=model_id,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    color_scheme='clusters',\n",
    "    font_sizes={'xtick_rotation': 0}, # Smaller font for many rotated ticks,\n",
    "    output_pdf_path=f'{model_id}_mha_heatmap.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP or Residual per Layer Probe Accuracies Line Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Dict, Any, Optional, List\n",
    "import os # Import os for directory operations\n",
    "\n",
    "def plot_layer_line(\n",
    "    accuracies: Dict[Any, float],\n",
    "    model_id: str,\n",
    "    num_layers: int, # Total number of layers in the model, used for xtick generation fallback\n",
    "    output_dir: Optional[str] = None, # Original parameter, noted as no longer used\n",
    "    activation_type: str = \"Activation\",\n",
    "    font_options: Optional[Dict[str, int]] = None,\n",
    "    pdf_output_path: Optional[str] = None # New parameter to specify PDF output path\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a line graph for layer-wise accuracies and shows it.\n",
    "    Optionally saves the plot as a PDF if pdf_output_path is provided.\n",
    "    The order of points in the line plot will depend on the iteration order\n",
    "    of the input 'accuracies' dictionary. This function does NOT sort the\n",
    "    accuracies data before plotting the line. Font sizes for plot elements\n",
    "    can be customized via the 'font_options' dictionary.\n",
    "\n",
    "    Args:\n",
    "        accuracies (Dict[Any, float]): Dictionary of layer accuracies.\n",
    "            Keys are layer identifiers, values are accuracies.\n",
    "            The plot will connect points in the dictionary's iteration order.\n",
    "        model_id (str): Identifier for the model, used in the plot title.\n",
    "        num_layers (int): Total number of actual layers in the model. This might be used\n",
    "                          as a fallback for determining x-axis tick marks if layer\n",
    "                          identifiers are numeric but sparse or not fully provided from `accuracies.keys()`.\n",
    "        output_dir (Optional[str]): No longer used. Kept for signature compatibility.\n",
    "        activation_type (str): Type of activation, used in the plot title.\n",
    "        font_options (Optional[Dict[str, int]]): Dictionary to customize font sizes.\n",
    "            Expected keys: 'title', 'axis_label', 'tick_label', 'legend_text'.\n",
    "            Example: {'title': 16, 'axis_label': 14, 'tick_label': 12, 'legend_text': 12}\n",
    "        pdf_output_path (Optional[str]): If provided, the path (including filename.pdf)\n",
    "            where the plot will be saved as a PDF. Example: \"plots/my_model_plot.pdf\".\n",
    "    \"\"\"\n",
    "    # (output_dir is no longer used, as per original comment)\n",
    "\n",
    "    # Define default font sizes\n",
    "    default_fonts = {\n",
    "        'title': 24,\n",
    "        'axis_label': 20,\n",
    "        'tick_label': 16,\n",
    "        'legend_text': 16,\n",
    "    }\n",
    "    # Update defaults with any user-provided font sizes\n",
    "    current_fonts = default_fonts.copy()\n",
    "    if font_options:\n",
    "        current_fonts.update(font_options)\n",
    "\n",
    "    print(f\"Generating Layer-wise line plot for {activation_type}...\")\n",
    "    if not accuracies:\n",
    "        print(f\"No data provided for {activation_type} layer-wise line plot.\")\n",
    "        return\n",
    "\n",
    "    # Prepare data for plotting.\n",
    "    # 'processed_layers' will store x-axis values (layer identifiers).\n",
    "    # 'accuracies_list' will store y-axis values (accuracies).\n",
    "    # Their order is determined by the 'accuracies' dictionary's iteration order.\n",
    "    keys_from_dict = list(accuracies.keys())\n",
    "    accuracies_list = list(accuracies.values())\n",
    "    \n",
    "    processed_layers: List[Any]\n",
    "    x_axis_is_numeric: bool\n",
    "\n",
    "    try:\n",
    "        processed_layers = [int(k) for k in keys_from_dict]\n",
    "        x_axis_is_numeric = True\n",
    "    except (ValueError, TypeError):\n",
    "        if all(isinstance(k, (int, float)) for k in keys_from_dict):\n",
    "            processed_layers = keys_from_dict\n",
    "            x_axis_is_numeric = True\n",
    "        else:\n",
    "            print(f\"Warning: Layer keys for {activation_type} plot are not uniformly integers or simple numeric types. Treating all layer identifiers as strings for categorical plotting.\")\n",
    "            processed_layers = [str(k) for k in keys_from_dict]\n",
    "            x_axis_is_numeric = False\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(processed_layers, accuracies_list, marker='o', linestyle='-', linewidth=2, markersize=8, color='#3366cc')\n",
    "    plt.axhline(y=50, color='r', linestyle='--', alpha=0.5, label='Chance level (50%)')\n",
    "\n",
    "    if accuracies_list:\n",
    "        best_layer_idx = np.argmax(accuracies_list)\n",
    "        best_layer_val = processed_layers[best_layer_idx]\n",
    "        best_accuracy_val = accuracies_list[best_layer_idx]\n",
    "        \n",
    "        plt.scatter(best_layer_val, best_accuracy_val, color='red', s=150, zorder=5,\n",
    "                    label=f'Best: Layer {best_layer_val} ({best_accuracy_val:.2f}%)')\n",
    "\n",
    "        min_val_for_ylim = min(accuracies_list)\n",
    "        max_val_for_ylim = max(accuracies_list)\n",
    "        plt.ylim(min(40, min_val_for_ylim - 5), max(90, max_val_for_ylim + 5))\n",
    "    else:\n",
    "        plt.ylim(35, 95)\n",
    "\n",
    "    plt.xlabel('Layer Number' if x_axis_is_numeric else 'Layer Identifier', fontsize=current_fonts['axis_label'])\n",
    "    plt.ylabel('Validation Accuracy (%)', fontsize=current_fonts['axis_label'])\n",
    "    plt.title(f'Probe Accuracy by Layer ({activation_type} output) - {model_id}', fontsize=current_fonts['title'])\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    if x_axis_is_numeric:\n",
    "        unique_numeric_layers = sorted(list(set(l for l in processed_layers if isinstance(l, (int, float)))))\n",
    "        if unique_numeric_layers:\n",
    "            tick_step = max(1, len(unique_numeric_layers) // 14 if len(unique_numeric_layers) > 14 else 1)\n",
    "            plt.xticks(ticks=unique_numeric_layers[::tick_step])\n",
    "        elif num_layers > 0:\n",
    "            step = max(1, num_layers // 14 if num_layers > 0 else 1)\n",
    "            plt.xticks(ticks=np.arange(0, num_layers, step))\n",
    "    else:\n",
    "        if len(processed_layers) > 10:\n",
    "             plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "    plt.tick_params(axis='both', which='major', labelsize=current_fonts['tick_label'])\n",
    "    plt.legend(loc='best', fontsize=current_fonts['legend_text'])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # --- SAVE PLOT AS PDF ---\n",
    "    if pdf_output_path:\n",
    "        try:\n",
    "            # Ensure the directory exists if pdf_output_path includes a directory\n",
    "            output_directory = os.path.dirname(pdf_output_path)\n",
    "            if output_directory and not os.path.exists(output_directory): # Check if output_directory is not empty\n",
    "                os.makedirs(output_directory)\n",
    "                print(f\"Created directory: {output_directory}\")\n",
    "            \n",
    "            plt.savefig(pdf_output_path, format='pdf', bbox_inches='tight')\n",
    "            print(f\"Plot saved as PDF to: {pdf_output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving plot to PDF at {pdf_output_path}: {e}\")\n",
    "    # --- END SAVE PLOT ---\n",
    "\n",
    "    plt.show()\n",
    "    plt.close() # Close figure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "model_id = 'llama'\n",
    "activation_type = 'residual'\n",
    "accuracies = pkl.load(open(f'linear_probe/trained_probe/{model_id}/accuracies_dict_{activation_type}.pkl', 'rb'))\n",
    "if 'gemma' in model_id:\n",
    "    NUM_HEADS = 8\n",
    "    NUM_LAYERS = 34\n",
    "else: # Assuming Llama-like structure otherwise\n",
    "    NUM_LAYERS = 28\n",
    "    NUM_HEADS = 24\n",
    "\n",
    "plot_layer_line(accuracies, model_id, NUM_LAYERS, NUM_HEADS, activation_type, pdf_output_path=f'{model_id}_{activation_type}_linechart.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import compute_accuracy\n",
    "import json\n",
    "model='gemma-3'\n",
    "TOP_K_HEADS=[16, 32, 48, 64]\n",
    "SCALES=[-20, -10, 10, 20]\n",
    "\n",
    "initial_accuracies = [] # list of list [[for strength in scales] for k in k_heads]\n",
    "final_accuracies = []\n",
    "shifts = []\n",
    "kl_divergences = [[0.03, 0.01, 0.01, 0.03], [0.07, 0.02, 0.03, 0.12], [0.12, 0.03, 0.04, 0.18], [0.15, 0.04, 0.05, 0.21]] # Computed in another program\n",
    "for k in TOP_K_HEADS:\n",
    "    current_k_initial_accuracies = []\n",
    "    current_k_final_accuracies = []\n",
    "    current_k_shifts = []\n",
    "    for strength in SCALES:\n",
    "        initial_predictions = []\n",
    "        with open(f'evaluation_jsonl/truthfulqa-{model}_initial_iti_{k}_{strength}.0.jsonl', 'r') as file:\n",
    "        # with open(f'evaluation_jsonl/truthfulqa-{model}_initial_base.jsonl', 'r') as file:\n",
    "            for line in file:\n",
    "                json_object = json.loads(line.strip())\n",
    "                initial_predictions.append(json_object['response']['body']['choices'][0]['message']['content'])\n",
    "\n",
    "        final_predictions = []\n",
    "        with open(f'evaluation_jsonl/truthfulqa-{model}_final_iti_{k}_{strength}.0.jsonl', 'r') as file:\n",
    "        # with open(f'evaluation_jsonl/truthfulqa-{model}_final_base.jsonl', 'r') as file:\n",
    "            for line in file:\n",
    "                json_object = json.loads(line.strip())\n",
    "                final_predictions.append(json_object['response']['body']['choices'][0]['message']['content'])\n",
    "\n",
    "        initial_accuracy = compute_accuracy(initial_predictions)\n",
    "        current_k_initial_accuracies.append(initial_accuracy)\n",
    "        final_accuracy = compute_accuracy(final_predictions)\n",
    "        current_k_final_accuracies.append(final_accuracy)\n",
    "        \n",
    "        correct_to_incorrect_count = 0\n",
    "        initial_correct_count = 0\n",
    "        for y1, y2 in zip(initial_predictions, final_predictions):\n",
    "            if y1 == \"CORRECT\" and y2 == \"INCORRECT\":\n",
    "                correct_to_incorrect_count+=1\n",
    "            if y1 == \"CORRECT\":\n",
    "                initial_correct_count+=1\n",
    "        shift = correct_to_incorrect_count/initial_correct_count\n",
    "        current_k_shifts.append(shift)\n",
    "    initial_accuracies.append(current_k_initial_accuracies)\n",
    "    final_accuracies.append(current_k_final_accuracies)\n",
    "    shifts.append(current_k_shifts)\n",
    "\n",
    "# initial_accuracies, final_accuracies, shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Font sizes\n",
    "title_fontsize = 24\n",
    "axis_label_fontsize = 24\n",
    "xtick_fontsize = 20  # Customizable X-tick font size\n",
    "ytick_fontsize = 20  # Customizable Y-tick font size\n",
    "annotation_fontsize = 25 # For heatmap cell annotations\n",
    "colorbar_label_fontsize = 20 # For the colorbar label\n",
    "colorbar_tick_fontsize = 20 # For the colorbar ticks\n",
    "\n",
    "# Figure and Plot settings\n",
    "figure_width = 10 # Adjusted slightly to accommodate colorbar better\n",
    "figure_height = 9\n",
    "heatmap_cmap = \"Greens\"\n",
    "heatmap_vmin = 0.3\n",
    "heatmap_vmax = 0.6\n",
    "heatmap_fmt = \".3f\"\n",
    "colorbar_label_text = \"\"\n",
    "tight_layout_pad = 1.5 # Padding for tight_layout\n",
    "\n",
    "# Output file\n",
    "output_filename = \"initial_accuracy_mha_hyperparam.pdf\"\n",
    "# --- End Customizable Parameters ---\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(initial_accuracies, index=TOP_K_HEADS, columns=SCALES)\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(figure_width, figure_height))\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = sns.heatmap(df,\n",
    "                      annot=True,\n",
    "                      cmap=heatmap_cmap,\n",
    "                      vmin=heatmap_vmin,\n",
    "                      vmax=heatmap_vmax,\n",
    "                      annot_kws={\"size\": annotation_fontsize, \"weight\": \"normal\"}, # Adjusted weight\n",
    "                      fmt=heatmap_fmt,\n",
    "                      cbar=True,  # Ensure colorbar is present\n",
    "                      cbar_kws={'label': colorbar_label_text} # Add label to colorbar\n",
    "                     )\n",
    "\n",
    "# Customize colorbar label font size and tick font size\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label(colorbar_label_text, fontsize=colorbar_label_fontsize)\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_fontsize)\n",
    "\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Effect of varying top k heads and intervention strength\\non initial accuracy for Gemma-3\",\n",
    "          fontsize=title_fontsize, pad=20) # Added some padding to title\n",
    "plt.xlabel(\"Intervention Strength\", fontsize=axis_label_fontsize, labelpad=10)\n",
    "plt.ylabel(\"Top k heads\", fontsize=axis_label_fontsize)\n",
    "\n",
    "# Set tick label font size\n",
    "plt.xticks(fontsize=xtick_fontsize, ha=\"right\") # Added rotation for better readability if scales are long\n",
    "plt.yticks(fontsize=ytick_fontsize, rotation=0)\n",
    "\n",
    "# Adjust layout to make sure everything fits\n",
    "plt.tight_layout(pad=tight_layout_pad)\n",
    "\n",
    "# Save the plot to PDF\n",
    "# It's often good to save before plt.show()\n",
    "# bbox_inches='tight' ensures the saved figure includes all elements without extra whitespace\n",
    "plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
    "print(f\"Plot saved to {output_filename}\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Font sizes\n",
    "title_fontsize = 24\n",
    "axis_label_fontsize = 24\n",
    "xtick_fontsize = 20  # Customizable X-tick font size\n",
    "ytick_fontsize = 20  # Customizable Y-tick font size\n",
    "annotation_fontsize = 25 # For heatmap cell annotations\n",
    "colorbar_label_fontsize = 20 # For the colorbar label\n",
    "colorbar_tick_fontsize = 20 # For the colorbar ticks\n",
    "\n",
    "# Figure and Plot settings\n",
    "figure_width = 10 # Adjusted slightly to accommodate colorbar better\n",
    "figure_height = 9\n",
    "heatmap_cmap = \"Greens\"\n",
    "heatmap_vmin = 0.3\n",
    "heatmap_vmax = 0.6\n",
    "heatmap_fmt = \".3f\"\n",
    "colorbar_label_text = \"\"\n",
    "tight_layout_pad = 1.5 # Padding for tight_layout\n",
    "\n",
    "# Output file\n",
    "output_filename = \"final_accuracy_mha_hyperparam.pdf\"\n",
    "# --- End Customizable Parameters ---\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(final_accuracies, index=TOP_K_HEADS, columns=SCALES)\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(figure_width, figure_height))\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = sns.heatmap(df,\n",
    "                      annot=True,\n",
    "                      cmap=heatmap_cmap,\n",
    "                      vmin=heatmap_vmin,\n",
    "                      vmax=heatmap_vmax,\n",
    "                      annot_kws={\"size\": annotation_fontsize, \"weight\": \"normal\"}, # Adjusted weight\n",
    "                      fmt=heatmap_fmt,\n",
    "                      cbar=True,  # Ensure colorbar is present\n",
    "                      cbar_kws={'label': colorbar_label_text} # Add label to colorbar\n",
    "                     )\n",
    "\n",
    "# Customize colorbar label font size and tick font size\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label(colorbar_label_text, fontsize=colorbar_label_fontsize)\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_fontsize)\n",
    "\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Effect of varying top k heads and intervention strength\\non final accuracy for Gemma-3\",\n",
    "          fontsize=title_fontsize, pad=20) # Added some padding to title\n",
    "plt.xlabel(\"Intervention Strength\", fontsize=axis_label_fontsize, labelpad=10)\n",
    "plt.ylabel(\"Top k heads\", fontsize=axis_label_fontsize)\n",
    "\n",
    "# Set tick label font size\n",
    "plt.xticks(fontsize=xtick_fontsize, ha=\"right\") # Added rotation for better readability if scales are long\n",
    "plt.yticks(fontsize=ytick_fontsize, rotation=0)\n",
    "\n",
    "# Adjust layout to make sure everything fits\n",
    "plt.tight_layout(pad=tight_layout_pad)\n",
    "\n",
    "# Save the plot to PDF\n",
    "# It's often good to save before plt.show()\n",
    "# bbox_inches='tight' ensures the saved figure includes all elements without extra whitespace\n",
    "plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
    "print(f\"Plot saved to {output_filename}\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Font sizes\n",
    "title_fontsize = 24\n",
    "axis_label_fontsize = 24\n",
    "xtick_fontsize = 20  # Customizable X-tick font size\n",
    "ytick_fontsize = 20  # Customizable Y-tick font size\n",
    "annotation_fontsize = 25 # For heatmap cell annotations\n",
    "colorbar_label_fontsize = 20 # For the colorbar label\n",
    "colorbar_tick_fontsize = 20 # For the colorbar ticks\n",
    "\n",
    "# Figure and Plot settings\n",
    "figure_width = 10 # Adjusted slightly to accommodate colorbar better\n",
    "figure_height = 9\n",
    "heatmap_cmap = \"Reds\"\n",
    "heatmap_vmin = 0.3\n",
    "heatmap_vmax = 0.6\n",
    "heatmap_fmt = \".3f\"\n",
    "colorbar_label_text = \"\"\n",
    "tight_layout_pad = 1.5 # Padding for tight_layout\n",
    "\n",
    "# Output file\n",
    "output_filename = \"shift_to_incorrect_mha_hyperparam.pdf\"\n",
    "# --- End Customizable Parameters ---\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(shifts, index=TOP_K_HEADS, columns=SCALES)\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(figure_width, figure_height))\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = sns.heatmap(df,\n",
    "                      annot=True,\n",
    "                      cmap=heatmap_cmap,\n",
    "                      vmin=heatmap_vmin,\n",
    "                      vmax=heatmap_vmax,\n",
    "                      annot_kws={\"size\": annotation_fontsize, \"weight\": \"normal\"}, # Adjusted weight\n",
    "                      fmt=heatmap_fmt,\n",
    "                      cbar=True,  # Ensure colorbar is present\n",
    "                      cbar_kws={'label': colorbar_label_text} # Add label to colorbar\n",
    "                     )\n",
    "\n",
    "# Customize colorbar label font size and tick font size\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label(colorbar_label_text, fontsize=colorbar_label_fontsize)\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_fontsize)\n",
    "\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Effect of varying top k heads and intervention strength\\non shift to incorrect rate for Gemma-3\",\n",
    "          fontsize=title_fontsize, pad=20) # Added some padding to title\n",
    "plt.xlabel(\"Intervention Strength\", fontsize=axis_label_fontsize, labelpad=10)\n",
    "plt.ylabel(\"Top k heads\", fontsize=axis_label_fontsize)\n",
    "\n",
    "# Set tick label font size\n",
    "plt.xticks(fontsize=xtick_fontsize, ha=\"right\") # Added rotation for better readability if scales are long\n",
    "plt.yticks(fontsize=ytick_fontsize, rotation=0)\n",
    "\n",
    "# Adjust layout to make sure everything fits\n",
    "plt.tight_layout(pad=tight_layout_pad)\n",
    "\n",
    "# Save the plot to PDF\n",
    "# It's often good to save before plt.show()\n",
    "# bbox_inches='tight' ensures the saved figure includes all elements without extra whitespace\n",
    "plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
    "print(f\"Plot saved to {output_filename}\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Font sizes\n",
    "title_fontsize = 24\n",
    "axis_label_fontsize = 24\n",
    "xtick_fontsize = 20  # Customizable X-tick font size\n",
    "ytick_fontsize = 20  # Customizable Y-tick font size\n",
    "annotation_fontsize = 25 # For heatmap cell annotations\n",
    "colorbar_label_fontsize = 18 # For the colorbar label\n",
    "colorbar_tick_fontsize = 20 # For the colorbar ticks\n",
    "\n",
    "# Figure and Plot settings\n",
    "figure_width = 10 # Adjusted slightly to accommodate colorbar better\n",
    "figure_height = 9\n",
    "heatmap_cmap = \"Reds\"\n",
    "heatmap_vmin = 0\n",
    "heatmap_vmax = 0.25\n",
    "heatmap_fmt = \".3f\"\n",
    "colorbar_label_text = \"\"\n",
    "tight_layout_pad = 1.5 # Padding for tight_layout\n",
    "\n",
    "# Output file\n",
    "output_filename = \"kl_divergences_mha_hyperparam.pdf\"\n",
    "# --- End Customizable Parameters ---\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(kl_divergences, index=TOP_K_HEADS, columns=SCALES)\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(figure_width, figure_height))\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = sns.heatmap(df,\n",
    "                      annot=True,\n",
    "                      cmap=heatmap_cmap,\n",
    "                      vmin=heatmap_vmin,\n",
    "                      vmax=heatmap_vmax,\n",
    "                      annot_kws={\"size\": annotation_fontsize, \"weight\": \"normal\"}, # Adjusted weight\n",
    "                      fmt=heatmap_fmt,\n",
    "                      cbar=True,  # Ensure colorbar is present\n",
    "                      cbar_kws={'label': colorbar_label_text} # Add label to colorbar\n",
    "                     )\n",
    "\n",
    "# Customize colorbar label font size and tick font size\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label(colorbar_label_text, fontsize=colorbar_label_fontsize)\n",
    "cbar.ax.tick_params(labelsize=colorbar_tick_fontsize)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Effect of varying top k heads and intervention strength\\non KL Divergences for Gemma-3\",\n",
    "          fontsize=title_fontsize, pad=20) # Added some padding to title\n",
    "plt.xlabel(\"Intervention Strength\", fontsize=axis_label_fontsize, labelpad=10)\n",
    "plt.ylabel(\"Top k heads\", fontsize=axis_label_fontsize)\n",
    "\n",
    "# Set tick label font size\n",
    "plt.xticks(fontsize=xtick_fontsize, ha=\"right\") # Added rotation for better readability if scales are long\n",
    "plt.yticks(fontsize=ytick_fontsize, rotation=0)\n",
    "\n",
    "# Adjust layout to make sure everything fits\n",
    "plt.tight_layout(pad=tight_layout_pad)\n",
    "\n",
    "# Save the plot to PDF\n",
    "# It's often good to save before plt.show()\n",
    "# bbox_inches='tight' ensures the saved figure includes all elements without extra whitespace\n",
    "plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
    "print(f\"Plot saved to {output_filename}\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual or MLP Intervention Strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd # Seaborn works well with pandas for grouped bar charts\n",
    "\n",
    "# --- ADJUSTABLE FONT SIZES ---\n",
    "TITLE_FONT_SIZE = 18\n",
    "LABEL_FONT_SIZE = 16\n",
    "TICK_FONT_SIZE = 14\n",
    "LEGEND_FONT_SIZE = 12\n",
    "\n",
    "# --- Simulate Data ---\n",
    "# Let's assume these are for an \"Residual Intervention\" scenario\n",
    "intervention_strengths = np.array([-20, -10, 0, 10, 20]) # 0 is no intervention\n",
    "n_strengths = len(intervention_strengths)\n",
    "\n",
    "initial_accuracy_residual = np.array([0.46341463414634143,\n",
    "   0.5304878048780488,\n",
    "   0.52,\n",
    "   0.5304878048780488,\n",
    "   0.47560975609756095])\n",
    "\n",
    "# Final Accuracy: Drops or stays same/worse than no-intervention (strength 0)\n",
    "final_accuracy_residual = np.array([0.36585365853658536, 0.38414634146341464,0.372, 0.3414634146341463, 0.33536585365853655])\n",
    "\n",
    "# Shift to Incorrect: No clear beneficial linear trend, might even worsen\n",
    "shift_to_incorrect_residual = np.array([0.4342105263157895,\n",
    "   0.4605263157894737,\n",
    "   0.517, # This is the baseline_shift_residual\n",
    "   0.4942528735632184,\n",
    "   0.47435897435897434])\n",
    "\n",
    "# --- Find No Intervention (Baseline) Data ---\n",
    "baseline_idx = np.where(intervention_strengths == 0)[0][0]\n",
    "baseline_initial_acc_residual = initial_accuracy_residual[baseline_idx]\n",
    "baseline_final_acc_residual = final_accuracy_residual[baseline_idx]\n",
    "baseline_shift_residual = shift_to_incorrect_residual[baseline_idx]\n",
    "\n",
    "# --- Plot Option 2: \"Delta from Baseline\" Line Plot ---\n",
    "delta_initial_accuracy_residual = initial_accuracy_residual - baseline_initial_acc_residual\n",
    "delta_final_accuracy_residual = final_accuracy_residual - baseline_final_acc_residual\n",
    "delta_shift_to_incorrect_residual = shift_to_incorrect_residual - baseline_shift_residual\n",
    "\n",
    "# --- Y-axis limit control ---\n",
    "# Determine min and max y values from the delta data\n",
    "all_delta_values = np.concatenate((delta_initial_accuracy_residual, delta_final_accuracy_residual, delta_shift_to_incorrect_residual))\n",
    "# Using hardcoded values as per your previous script for data_min_y and data_max_y\n",
    "# If you want to dynamically calculate them from all_delta_values:\n",
    "data_min_y = np.min(all_delta_values)\n",
    "data_max_y = np.max(all_delta_values)\n",
    "\n",
    "# --- ADJUSTABLE Y-LIMITS ---\n",
    "# Set to True to use manual y_min and y_max, False for automatic padding\n",
    "USE_MANUAL_YLIMITS = False # <--- CHANGE THIS TO True TO USE MANUAL VALUES\n",
    "MANUAL_Y_MIN = -0.10   # <--- SET YOUR DESIRED MIN Y VALUE HERE\n",
    "MANUAL_Y_MAX = 0.10    # <--- SET YOUR DESIRED MAX Y VALUE HERE\n",
    "PADDING_FACTOR = 0.1 # 10% padding if not using manual limits\n",
    "\n",
    "if USE_MANUAL_YLIMITS:\n",
    "    plot_y_min = MANUAL_Y_MIN\n",
    "    plot_y_max = MANUAL_Y_MAX\n",
    "else:\n",
    "    y_range = data_max_y - data_min_y\n",
    "    if y_range == 0: # Handle case where all delta values are the same (e.g., all zero)\n",
    "        padding = 0.1 # Default padding if range is zero\n",
    "    else:\n",
    "        padding = y_range * PADDING_FACTOR\n",
    "\n",
    "    plot_y_min = data_min_y - padding\n",
    "    plot_y_max = data_max_y + padding\n",
    "    # Ensure 0 is nicely visible if it's within the padded range or close\n",
    "    if plot_y_min < 0 < plot_y_max:\n",
    "        abs_max_delta = max(abs(plot_y_min), abs(plot_y_max))\n",
    "        plot_y_min = -abs_max_delta\n",
    "        plot_y_max = abs_max_delta\n",
    "    elif plot_y_min > -padding/2:\n",
    "        plot_y_min = min(plot_y_min, -padding/2)\n",
    "    elif plot_y_max < padding/2:\n",
    "        plot_y_max = max(plot_y_max, padding/2)\n",
    "\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "ax2.plot(intervention_strengths, delta_initial_accuracy_residual, marker='o', linestyle='-', label='Δ Initial Accuracy from Baseline', color='cornflowerblue', linewidth=2)\n",
    "ax2.plot(intervention_strengths, delta_final_accuracy_residual, marker='o', linestyle='-', label='Δ Final Accuracy from Baseline', color='forestgreen', linewidth=2)\n",
    "ax2.plot(intervention_strengths, delta_shift_to_incorrect_residual, marker='o', linestyle='-', label='Δ Shift to Incorrect from Baseline', color='crimson', linewidth=2)\n",
    "\n",
    "ax2.axhline(0, color='darkgrey', linewidth=1.0, linestyle='--', label='Baseline (No Change)')\n",
    "\n",
    "# --- Apply Font Sizes ---\n",
    "ax2.set_xlabel('Intervention Strength', fontsize=LABEL_FONT_SIZE)\n",
    "ax2.set_ylabel('Change from Baseline Value', fontsize=LABEL_FONT_SIZE)\n",
    "ax2.set_title('Delta from Baseline for Residual Stream Intervention', fontsize=TITLE_FONT_SIZE)\n",
    "\n",
    "# Apply font size to tick labels\n",
    "ax2.tick_params(axis='both', which='major', labelsize=TICK_FONT_SIZE)\n",
    "\n",
    "# Apply the determined y-limits\n",
    "ax2.set_ylim(plot_y_min, plot_y_max)\n",
    "\n",
    "ax2.legend(fontsize=LEGEND_FONT_SIZE)\n",
    "# ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "ax2.grid(True, linestyle=':', alpha=0.6, color='lightgray')\n",
    "fig2.tight_layout() # Adjust layout to prevent overlapping labels\n",
    "\n",
    "# Save the figure before showing it\n",
    "plt.savefig('residual_intervention_strength.pdf', bbox_inches='tight') # Added bbox_inches='tight'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd # Seaborn works well with pandas for grouped bar charts\n",
    "\n",
    "# --- ADJUSTABLE FONT SIZES ---\n",
    "TITLE_FONT_SIZE = 18\n",
    "LABEL_FONT_SIZE = 16\n",
    "TICK_FONT_SIZE = 14\n",
    "LEGEND_FONT_SIZE = 12\n",
    "\n",
    "\n",
    "# --- Simulate Data ---\n",
    "# Let's assume these are for an \"MLP Intervention\" scenario\n",
    "intervention_strengths = np.array([-20, -10, 0, 10, 20]) # 0 is no intervention\n",
    "n_strengths = len(intervention_strengths)\n",
    "\n",
    "initial_accuracy_mlp = np.array([0.4512195121951219,\n",
    "   0.47560975609756095,\n",
    "   0.52,\n",
    "   0.47560975609756095,\n",
    "   0.4024390243902439])\n",
    "final_accuracy_mlp = np.array([0.300, 0.370, 0.370, 0.430, 0.320])\n",
    "shift_to_incorrect_mlp = np.array([0.550, 0.480, 0.510, 0.350, 0.490])\n",
    "\n",
    "baseline_idx = np.where(intervention_strengths == 0)[0][0]\n",
    "baseline_init_acc_mlp = initial_accuracy_mlp[baseline_idx]\n",
    "baseline_final_acc_mlp = final_accuracy_mlp[baseline_idx]\n",
    "baseline_shift_mlp = shift_to_incorrect_mlp[baseline_idx]\n",
    "\n",
    "# --- Plot Option 2: \"Delta from Baseline\" Line Plot ---\n",
    "delta_initial_accuracy_mlp = initial_accuracy_mlp - baseline_init_acc_mlp\n",
    "delta_final_accuracy_mlp = final_accuracy_mlp - baseline_final_acc_mlp\n",
    "delta_shift_to_incorrect_mlp = shift_to_incorrect_mlp - baseline_shift_mlp\n",
    "\n",
    "# --- Y-axis limit control ---\n",
    "# Option 1: Automatic padding (calculates min/max from data and adds some space)\n",
    "# Option 2: Manual override (set specific values)\n",
    "\n",
    "# Determine min and max y values from the delta data\n",
    "all_delta_values = np.concatenate((delta_initial_accuracy_mlp, delta_final_accuracy_mlp, delta_shift_to_incorrect_mlp))\n",
    "data_min_y = np.min(all_delta_values)\n",
    "data_max_y = np.max(all_delta_values)\n",
    "\n",
    "# --- ADJUSTABLE Y-LIMITS ---\n",
    "# Set to True to use manual y_min and y_max, False for automatic padding\n",
    "USE_MANUAL_YLIMITS = False # <--- CHANGE THIS TO True TO USE MANUAL VALUES\n",
    "MANUAL_Y_MIN = -0.10   # <--- SET YOUR DESIRED MIN Y VALUE HERE\n",
    "MANUAL_Y_MAX = 0.10    # <--- SET YOUR DESIRED MAX Y VALUE HERE\n",
    "PADDING_FACTOR = 0.1 # 10% padding if not using manual limits\n",
    "\n",
    "if USE_MANUAL_YLIMITS:\n",
    "    plot_y_min = MANUAL_Y_MIN\n",
    "    plot_y_max = MANUAL_Y_MAX\n",
    "else:\n",
    "    y_range = data_max_y - data_min_y\n",
    "    if y_range == 0: # Handle case where all delta values are the same (e.g., all zero)\n",
    "        padding = 0.1 # Default padding if range is zero\n",
    "    else:\n",
    "        padding = y_range * PADDING_FACTOR\n",
    "\n",
    "    plot_y_min = data_min_y - padding\n",
    "    plot_y_max = data_max_y + padding\n",
    "    # Ensure 0 is nicely visible if it's within the padded range or close\n",
    "    if plot_y_min < 0 < plot_y_max:\n",
    "        # If 0 is within the range, try to make the plot symmetrical if sensible\n",
    "        # or at least ensure 0 isn't too close to an edge.\n",
    "        # This is a simple heuristic, can be refined.\n",
    "        abs_max_delta = max(abs(plot_y_min), abs(plot_y_max))\n",
    "        plot_y_min = -abs_max_delta\n",
    "        plot_y_max = abs_max_delta\n",
    "    elif plot_y_min > -padding/2: # if min is very close to 0 from below\n",
    "        plot_y_min = min(plot_y_min, -padding/2) # push it a bit further from 0\n",
    "    elif plot_y_max < padding/2: # if max is very close to 0 from above\n",
    "        plot_y_max = max(plot_y_max, padding/2) # push it a bit further from 0\n",
    "\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax2.plot(intervention_strengths, delta_initial_accuracy_mlp, marker='o', linestyle='-', label='Δ Initial Accuracy from Baseline', color='cornflowerblue', linewidth=2)\n",
    "ax2.plot(intervention_strengths, delta_final_accuracy_mlp, marker='o', linestyle='-', label='Δ Final Accuracy from Baseline', color='forestgreen', linewidth=2)\n",
    "ax2.plot(intervention_strengths, delta_shift_to_incorrect_mlp, marker='o', linestyle='-', label='Δ Shift to Incorrect from Baseline', color='crimson', linewidth=2)\n",
    "\n",
    "ax2.axhline(0, color='darkgrey', linewidth=1.0, linestyle='--', label='Baseline (No Change)') # Made baseline more prominent\n",
    "# --- Apply Font Sizes ---\n",
    "ax2.set_xlabel('Intervention Strength', fontsize=LABEL_FONT_SIZE)\n",
    "ax2.set_ylabel('Change from Baseline Value', fontsize=LABEL_FONT_SIZE)\n",
    "ax2.set_title('Delta from Baseline for MLP Intervention', fontsize=TITLE_FONT_SIZE)\n",
    "\n",
    "# Apply font size to tick labels\n",
    "ax2.tick_params(axis='both', which='major', labelsize=TICK_FONT_SIZE)\n",
    "\n",
    "# Apply the determined y-limits\n",
    "ax2.set_ylim(plot_y_min, plot_y_max)\n",
    "\n",
    "ax2.legend(fontsize=LEGEND_FONT_SIZE)\n",
    "# ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "ax2.grid(True, linestyle=':', alpha=0.6, color='lightgray')\n",
    "fig2.tight_layout() # Adjust layout to prevent overlapping labels\n",
    "plt.savefig('mlp_intervention_strength.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- ADJUSTABLE FONT SIZES ---\n",
    "TITLE_FONT_SIZE = 16\n",
    "SUBPLOT_TITLE_FONT_SIZE = 14\n",
    "LABEL_FONT_SIZE = 12\n",
    "TICK_FONT_SIZE = 10\n",
    "LEGEND_FONT_SIZE = 10\n",
    "\n",
    "# --- COLORS (Inspired by common academic plots and paper's use of distinct colors) ---\n",
    "COLOR_MLP = '#1f77b4'  # Blue\n",
    "COLOR_RESIDUAL = '#2ca02c' # Green\n",
    "COLOR_MHA = '#d62728' # Red (often used for emphasis or a key comparison)\n",
    "COLOR_BASELINE_HLINE = 'darkgrey' # For the y=0 horizontal line\n",
    "\n",
    "# --- LINE WIDTHS ---\n",
    "LINEWIDTH_STD = 1.8\n",
    "LINEWIDTH_EMPHASIS = 2.5 # For MHA if it's the focus\n",
    "LINEWIDTH_BASELINE_HLINE = 1.0\n",
    "\n",
    "# --- Intervention Strengths (Assuming same for all for comparison) ---\n",
    "intervention_strengths = np.array([-20, -15, -10, -5, 0, 5, 10, 15, 20]) # Extended for smoother plot\n",
    "\n",
    "# --- Simulated/Placeholder Data (Extended to match new intervention_strengths) ---\n",
    "original_strengths = np.array([-20, -10, 0, 10, 20])\n",
    "\n",
    "# MLP Data\n",
    "original_initial_accuracy_mlp = np.array([0.4512195121951219, 0.47560975609756095, 0.52, 0.47560975609756095, 0.4024390243902439])\n",
    "original_shift_to_incorrect_mlp = np.array([0.550, 0.480, 0.510, 0.350, 0.490])\n",
    "\n",
    "# Residual Stream Data\n",
    "original_initial_accuracy_residual = np.array([0.46341463414634143, 0.5304878048780488, 0.52, 0.5304878048780488, 0.47560975609756095])\n",
    "original_shift_to_incorrect_residual = np.array([0.4342105263157895, 0.4605263157894737, 0.517, 0.4942528735632184, 0.47435897435897434])\n",
    "\n",
    "# MHA Data\n",
    "original_initial_accuracy_mha = np.array([0.55, 0.55, 0.523, 0.522, 0.50])\n",
    "original_shift_to_incorrect_mha = np.array([0.34, 0.34, 0.41, 0.48, 0.44])\n",
    "\n",
    "# Interpolate data for smoother plot\n",
    "initial_accuracy_mlp = np.interp(intervention_strengths, original_strengths, original_initial_accuracy_mlp)\n",
    "shift_to_incorrect_mlp = np.interp(intervention_strengths, original_strengths, original_shift_to_incorrect_mlp)\n",
    "\n",
    "initial_accuracy_residual = np.interp(intervention_strengths, original_strengths, original_initial_accuracy_residual)\n",
    "shift_to_incorrect_residual = np.interp(intervention_strengths, original_strengths, original_shift_to_incorrect_residual)\n",
    "\n",
    "initial_accuracy_mha = np.interp(intervention_strengths, original_strengths, original_initial_accuracy_mha)\n",
    "shift_to_incorrect_mha = np.interp(intervention_strengths, original_strengths, original_shift_to_incorrect_mha)\n",
    "\n",
    "\n",
    "# --- Calculate Baselines (Value at Intervention Strength 0) ---\n",
    "baseline_idx = np.where(intervention_strengths == 0)[0][0]\n",
    "\n",
    "baseline_initial_acc_mlp = initial_accuracy_mlp[baseline_idx]\n",
    "baseline_shift_mlp = shift_to_incorrect_mlp[baseline_idx]\n",
    "\n",
    "baseline_initial_acc_residual = initial_accuracy_residual[baseline_idx]\n",
    "baseline_shift_residual = shift_to_incorrect_residual[baseline_idx]\n",
    "\n",
    "baseline_initial_acc_mha = initial_accuracy_mha[baseline_idx]\n",
    "baseline_shift_mha = shift_to_incorrect_mha[baseline_idx]\n",
    "\n",
    "# --- Calculate Deltas from Baseline ---\n",
    "# Shift to Incorrect (signed)\n",
    "delta_shift_mlp = shift_to_incorrect_mlp - baseline_shift_mlp\n",
    "delta_shift_residual = shift_to_incorrect_residual - baseline_shift_residual\n",
    "delta_shift_mha = shift_to_incorrect_mha - baseline_shift_mha\n",
    "\n",
    "# Initial Accuracy (absolute delta)\n",
    "abs_delta_initial_acc_mlp = np.abs(initial_accuracy_mlp - baseline_initial_acc_mlp)\n",
    "abs_delta_initial_acc_residual = np.abs(initial_accuracy_residual - baseline_initial_acc_residual)\n",
    "abs_delta_initial_acc_mha = np.abs(initial_accuracy_mha - baseline_initial_acc_mha)\n",
    "\n",
    "\n",
    "# --- Create the 2x1 Subplot Figure ---\n",
    "fig, axs = plt.subplots(2, 1, figsize=(8, 8), sharex=True) # Adjusted figsize for better aspect ratio\n",
    "\n",
    "# --- Plot 1: Delta Shift to Incorrect ---\n",
    "ax1 = axs[0]\n",
    "ax1.plot(intervention_strengths, delta_shift_mlp, label='MLP', color=COLOR_MLP, linewidth=LINEWIDTH_STD, marker='o', markersize=4, alpha=0.8)\n",
    "ax1.plot(intervention_strengths, delta_shift_residual, label='Residual', color=COLOR_RESIDUAL, linewidth=LINEWIDTH_STD, marker='s', markersize=4, alpha=0.8)\n",
    "ax1.plot(intervention_strengths, delta_shift_mha, label='MHA', color=COLOR_MHA, linewidth=LINEWIDTH_EMPHASIS, marker='^', markersize=5, alpha=0.8)\n",
    "\n",
    "ax1.axhline(0, color=COLOR_BASELINE_HLINE, linewidth=LINEWIDTH_BASELINE_HLINE, linestyle='--', label='Baseline (No Change)')\n",
    "ax1.set_ylabel('Δ Shift to Incorrect\\n(Lower is Better)', fontsize=LABEL_FONT_SIZE)\n",
    "ax1.set_title('Impact on Sycophancy (Shift to Incorrect)', fontsize=SUBPLOT_TITLE_FONT_SIZE)\n",
    "ax1.legend(fontsize=LEGEND_FONT_SIZE, loc='best', frameon=False) # Changed loc for potentially better placement\n",
    "ax1.grid(True, linestyle=':', alpha=0.6, color='lightgray')\n",
    "ax1.tick_params(axis='y', labelsize=TICK_FONT_SIZE)\n",
    "\n",
    "# --- Plot 2: Absolute Delta Initial Accuracy ---\n",
    "ax2 = axs[1]\n",
    "ax2.plot(intervention_strengths, abs_delta_initial_acc_mlp, label='MLP', color=COLOR_MLP, linewidth=LINEWIDTH_STD, marker='o', markersize=4, alpha=0.8)\n",
    "ax2.plot(intervention_strengths, abs_delta_initial_acc_residual, label='Residual', color=COLOR_RESIDUAL, linewidth=LINEWIDTH_STD, marker='s', markersize=4, alpha=0.8)\n",
    "ax2.plot(intervention_strengths, abs_delta_initial_acc_mha, label='MHA', color=COLOR_MHA, linewidth=LINEWIDTH_EMPHASIS, marker='^', markersize=5, alpha=0.8)\n",
    "\n",
    "# ax2.axhline(0, color=COLOR_BASELINE_HLINE, linewidth=LINEWIDTH_BASELINE_HLINE, linestyle='--', label='No Change from Baseline') # Baseline is now the x-axis\n",
    "ax2.set_xlabel('Intervention Strength', fontsize=LABEL_FONT_SIZE)\n",
    "ax2.set_ylabel('|Δ Initial Accuracy|\\n(Lower is Better)', fontsize=LABEL_FONT_SIZE)\n",
    "ax2.set_title('Magnitude of Impact on Initial Accuracy', fontsize=SUBPLOT_TITLE_FONT_SIZE)\n",
    "# ax2.legend(fontsize=LEGEND_FONT_SIZE, loc='best', frameon=False) # Legend can be omitted if clear from above\n",
    "ax2.grid(True, linestyle=':', alpha=0.6, color='lightgray')\n",
    "ax2.tick_params(axis='both', labelsize=TICK_FONT_SIZE)\n",
    "\n",
    "\n",
    "# --- Overall Figure Title and Layout ---\n",
    "fig.suptitle('Comparative Effect of Intervention Strategies vs. Strength', fontsize=TITLE_FONT_SIZE, y=0.98)\n",
    "fig.tight_layout(rect=[0, 0.02, 1, 0.95]) # rect adjusts for suptitle and bottom x-label\n",
    "\n",
    "# --- Y-axis limit control ---\n",
    "def get_padded_limits_signed(data_values, padding_factor=0.15, symmetrize_around_zero=True):\n",
    "    # Add 0 to data_values to ensure baseline is considered for range calculation\n",
    "    data_values_with_zero = np.append(data_values, 0)\n",
    "    min_val_eff = np.min(data_values_with_zero)\n",
    "    max_val_eff = np.max(data_values_with_zero)\n",
    "\n",
    "    data_range = max_val_eff - min_val_eff\n",
    "    if data_range == 0: data_range = abs(min_val_eff) * 0.2 if abs(min_val_eff) > 0 else 0.2\n",
    "    \n",
    "    padding = data_range * padding_factor\n",
    "    plot_min = min_val_eff - padding\n",
    "    plot_max = max_val_eff + padding\n",
    "    \n",
    "    if symmetrize_around_zero and plot_min < 0 < plot_max:\n",
    "        abs_extreme = max(abs(plot_min), abs(plot_max))\n",
    "        return -abs_extreme, abs_extreme\n",
    "    elif symmetrize_around_zero and plot_min >= 0 and plot_max >=0: # all positive\n",
    "        return max(plot_min - padding, -0.01), plot_max # Ensure 0 is slightly visible if min is near 0\n",
    "    elif symmetrize_around_zero and plot_min <= 0 and plot_max <=0: # all negative\n",
    "        return plot_min, min(plot_max + padding, 0.01)\n",
    "        \n",
    "    return plot_min, plot_max\n",
    "\n",
    "def get_padded_limits_abs(data_values, padding_factor=0.1):\n",
    "    # For absolute values, the minimum is 0 (or very close to it)\n",
    "    min_val_eff = 0 # Or np.min(data_values) if you don't want to force 0\n",
    "    max_val_eff = np.max(data_values)\n",
    "    \n",
    "    data_range = max_val_eff - min_val_eff # min_val_eff is 0\n",
    "    if data_range == 0: data_range = max_val_eff * 0.2 if max_val_eff > 0 else 0.1 # handle if all values are 0\n",
    "\n",
    "    padding = data_range * padding_factor\n",
    "    plot_min = -padding * 0.1 # Start slightly below 0 for visual spacing\n",
    "    plot_max = max_val_eff + padding\n",
    "    return plot_min, plot_max\n",
    "\n",
    "\n",
    "all_delta_shift_values = np.concatenate((delta_shift_mlp, delta_shift_residual, delta_shift_mha))\n",
    "all_abs_delta_acc_values = np.concatenate((abs_delta_initial_acc_mlp, abs_delta_initial_acc_residual, abs_delta_initial_acc_mha))\n",
    "\n",
    "y_lim_shift = get_padded_limits_signed(all_delta_shift_values, symmetrize_around_zero=True)\n",
    "y_lim_abs_acc = get_padded_limits_abs(all_abs_delta_acc_values)\n",
    "\n",
    "\n",
    "ax1.set_ylim(y_lim_shift)\n",
    "ax2.set_ylim(y_lim_abs_acc)\n",
    "\n",
    "\n",
    "# --- Save and Show ---\n",
    "plt.savefig('intervention_comparison_trends.pdf', bbox_inches='tight')\n",
    "# plt.savefig('intervention_comparison_trends_abs_acc.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sankey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model = 'gemma-3'\n",
    "k = 64\n",
    "strength = -20\n",
    "initial_state = []\n",
    "# with open(f'evaluation_jsonl/truthfulqa-{model}_initial_iti_{k}_{strength}.0.jsonl', 'r') as file:\n",
    "with open(f'evaluation_jsonl/truthfulqa-{model}_initial_base.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        json_object = json.loads(line.strip())\n",
    "        initial_state.append(json_object['response']['body']['choices'][0]['message']['content'])\n",
    "\n",
    "final_state = []\n",
    "# with open(f'evaluation_jsonl/truthfulqa-{model}_final_iti_{k}_{strength}.0.jsonl', 'r') as file:\n",
    "with open(f'evaluation_jsonl/truthfulqa-{model}_final_base.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        json_object = json.loads(line.strip())\n",
    "        final_state.append(json_object['response']['body']['choices'][0]['message']['content'])\n",
    "\n",
    "stay_correct, correct_to_incorrect, incorrect_to_correct, stay_incorrect = 0, 0, 0, 0\n",
    "correct_to_incorrect_ids = []\n",
    "incorrect_to_correct_ids = []\n",
    "for i, (initial, final) in enumerate(zip(initial_state, final_state)):\n",
    "    if initial == 'CORRECT' and final == 'CORRECT':\n",
    "        stay_correct += 1\n",
    "    elif initial == 'CORRECT' and final == 'INCORRECT':\n",
    "        correct_to_incorrect += 1\n",
    "        correct_to_incorrect_ids.append(i)\n",
    "    elif initial == 'INCORRECT' and final == 'CORRECT':\n",
    "        incorrect_to_correct += 1\n",
    "        incorrect_to_correct_ids.append(i)\n",
    "    elif initial == 'INCORRECT' and final == 'INCORRECT':\n",
    "        stay_incorrect += 1\n",
    "\n",
    "print(stay_correct, correct_to_incorrect, incorrect_to_correct, stay_incorrect)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Configure Kaleido to not load MathJax\n",
    "pio.kaleido.scope.mathjax = None\n",
    "\n",
    "# Define nodes\n",
    "nodes = [\"Correct (Initial)\", \"Incorrect (Initial)\", \"Correct (Final)\", \"Incorrect (Final)\"]\n",
    "\n",
    "# Define links (source, target, value)\n",
    "links = {\n",
    "    \"source\": [0, 0, 1, 1],\n",
    "    \"target\": [2, 3, 2, 3],\n",
    "    \"value\": [stay_correct, correct_to_incorrect, incorrect_to_correct, stay_incorrect],\n",
    "}\n",
    " \n",
    "correct_color = \"rgba(162, 210, 162, 0.45)\" # Soft emerald green\n",
    "incorrect_color = \"rgba(255, 160, 122, 0.45)\" # Light salmon\n",
    "correct_to_incorrect = \"rgba(255, 160, 122, 0.8)\" # Light sky-blue\n",
    "incorrect_to_correct = \"rgba(173, 216, 230, 0.45)\" # Soft emerald green\n",
    "\n",
    "node_colors = [\n",
    "    correct_color,  # Correct Initial  \n",
    "    incorrect_color,  # Incorrect Initial  \n",
    "    correct_color,  # Correct Final  \n",
    "    incorrect_color,  # Incorrect Final  \n",
    "]\n",
    "\n",
    "link_colors = [\n",
    "    correct_color,  # Correct Always  \n",
    "    correct_to_incorrect,  # Correct Always\n",
    "    incorrect_to_correct,  # Incorrect Always\n",
    "    incorrect_color,  # Incorrect Always\n",
    "]\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        label=nodes,\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        color=node_colors,\n",
    "        line=dict(color=\"rgba(50, 50, 50, 0.2)\", width=0.5)\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=links[\"source\"],\n",
    "        target=links[\"target\"],\n",
    "        value=links[\"value\"],\n",
    "        color=link_colors\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(family=\"Inter, -apple-system, Arial, sans-serif\",\n",
    "              size=10),  # Increased font size from 12 to 16, removed global color\n",
    "    width=360,  # Slightly increased width to accommodate larger text\n",
    "    height=200,  # Slightly increased height\n",
    "    margin=dict(l=25, r=25, t=30, b=25),\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "# Make node labels more visible with bold font, appropriate colors, and text outline\n",
    "# Using CSS text-shadow to create an outline effect around the text\n",
    "node_text_colors = [\"darkgrey\", \"darkgrey\", \"darkgrey\", \"darkgrey\"]  # Color for each node's text\n",
    "outline_colors = [\"darkgrey\", \"darkgrey\", \"darkgrey\", \"darkgrey\"]  # Outline color for each node's text\n",
    "\n",
    "\n",
    "# Font Style 1 \n",
    "# fig.update_traces(\n",
    "#     node=dict(\n",
    "#         label=[f'<b><span style=\"color: {text_color}; text-shadow: -1px -1px 0 {outline}, 1px -1px 0 {outline}, -1px 1px 0 {outline}, 1px 1px 0 {outline}, 0px 1px 0 {outline}, 0px -1px 0 {outline}, 1px 0px 0 {outline}, -1px 0px 0 {outline};\">{label}</span></b>' \n",
    "#                for label, text_color, outline in zip(nodes, node_text_colors, outline_colors)],\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# Font Style 2\n",
    "# fig.update_traces(\n",
    "#     node=dict(\n",
    "#         label=[f'<span style=\"font-family: Inter, -apple-system, Arial, sans-serif; font-weight: 600; color: {text_color}; text-shadow: 0px 0px 2px {outline};\">{label}</span>' \n",
    "#                for label, text_color, outline in zip(nodes, node_text_colors, outline_colors)],\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# Saving the figure\n",
    "output_pdf_file = \"sankey_diagram.pdf\"\n",
    "try:\n",
    "    fig.write_image(output_pdf_file)\n",
    "    print(f\"Figure saved as {output_pdf_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving figure: {e}\")\n",
    "    print(\"Make sure you have kaleido installed: pip install -U kaleido\")\n",
    "\n",
    "# Display the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Head Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rifo.genadi/.conda/envs/sycophancy/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:818: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c50d058306484d95982469e7670688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "accuracies = pickle.load(open('/home/rifo.genadi/Documents/sycophancy_exploration/linear_probe/trained_probe/gemma-3/accuracies_dict_mha.pkl', 'rb'))\n",
    "sorted_items = sorted(accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"truthfulqa/truthful_qa\", \"generation\")\n",
    "ds_train = ds['validation'][:int(0.8*len(ds['validation']))]\n",
    "questions = ds_train['question']\n",
    "correct_answers = ds_train['correct_answers']\n",
    "incorrect_answers = ds_train['incorrect_answers']\n",
    "\n",
    "from linear_probe.linear_probe_data_utils import construct_data\n",
    "chats, labels = construct_data(ds_train, model='gemma')\n",
    "\n",
    "from bertviz import model_view, head_view\n",
    "from transformers import Gemma3ForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "\n",
    "# Load model and processor\n",
    "model = Gemma3ForConditionalGeneration.from_pretrained(\"google/gemma-3-4b-it\", device_map=\"auto\", output_attentions=True)\n",
    "processor = AutoProcessor.from_pretrained(\"google/gemma-3-4b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups(tokens):\n",
    "    \"\"\"\n",
    "    Returns a list of tuples, where each tuple is (start_idx, end_idx (exclusive), group_name).\n",
    "    \"\"\"\n",
    "    token_groups = []\n",
    "\n",
    "    # get bos group start and end token\n",
    "    bos_start = tokens.index(\"<bos>\")\n",
    "    bos_end = tokens.index(\"<start_of_turn>\")\n",
    "    token_groups.append((bos_start, bos_end, \"BOS\"))\n",
    "\n",
    "    # get system prompt group start and end token\n",
    "    sys_prompt_start = bos_end\n",
    "    sys_prompt_end = tokens.index(\"<start_of_turn>\", sys_prompt_start+1)\n",
    "    token_groups.append((sys_prompt_start, sys_prompt_end, \"System Prompt\"))\n",
    "\n",
    "    # first ans\n",
    "    first_response_start = sys_prompt_end\n",
    "    first_response_end = tokens.index(\"<start_of_turn>\", first_response_start+1)\n",
    "    token_groups.append((first_response_start, first_response_end, \"First Response\"))\n",
    "\n",
    "    # disagreement\n",
    "    disagreement_start = first_response_end+3\n",
    "    disagreement_end = tokens.index(\"?\", disagreement_start+1)+1\n",
    "    token_groups.append((disagreement_start, disagreement_end, \"Disagreement\"))\n",
    "\n",
    "    # instruction in challenge\n",
    "    instruction_start = disagreement_end\n",
    "    instruction_end = tokens.index(\"<start_of_turn>\", instruction_start+1)-1\n",
    "    token_groups.append((instruction_start, instruction_end, \"Instruction\"))\n",
    "\n",
    "    # final response\n",
    "    final_response_start = instruction_end + 2\n",
    "    final_response_end = tokens.index(\"<end_of_turn>\", final_response_start+1)\n",
    "    token_groups.append((final_response_start, final_response_end, \"Final Response\"))\n",
    "\n",
    "    return token_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [('14_7', 97.70992366412214),\n",
    "#  ('15_2', 96.94656488549619),\n",
    "#  ('13_1', 96.56488549618321),\n",
    "#  ('15_3', 96.18320610687023),\n",
    "#  ('13_0', 95.80152671755725),\n",
    "#  ('16_0', 95.80152671755725),\n",
    "#  ('18_4', 94.27480916030534),\n",
    "#  ('8_2', 93.12977099236642),\n",
    "#  ('7_0', 92.74809160305344),\n",
    "#  ('8_6', 92.74809160305344),\n",
    "#  ('10_1', 92.36641221374046),\n",
    "#  ('5_1', 91.6030534351145),\n",
    "#  ('10_0', 91.6030534351145),\n",
    "#  ('14_6', 91.6030534351145),\n",
    "#  ('12_2', 90.83969465648855),\n",
    "#  ('21_3', 90.83969465648855),\n",
    "#  ('4_6', 90.07633587786259),\n",
    "#  ('13_4', 90.07633587786259),\n",
    "#  ('18_5', 90.07633587786259),\n",
    "#  ('33_7', 90.07633587786259),\n",
    "#  ('12_1', 89.69465648854961),\n",
    "#  ('14_0', 89.69465648854961),\n",
    "#  ('18_0', 89.69465648854961),\n",
    "#  ('4_5', 89.31297709923665),\n",
    "#  ('5_3', 89.31297709923665),\n",
    "# ...\n",
    "#  ('32_1', 53.81679389312977),\n",
    "#  ('24_1', 53.05343511450382),\n",
    "#  ('24_5', 52.67175572519084),\n",
    "#  ('28_1', 52.67175572519084),\n",
    "#  ('30_0', 51.52671755725191)]\n",
    "\n",
    "from transformers import utils\n",
    "from bertviz import model_view\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "\n",
    "tokenizer = processor.tokenizer\n",
    "query = tokenizer.apply_chat_template(chats[0], add_generation_prompt=False, tokenize=False)\n",
    "# inputs = processor.tokenizer(query, return_tensors=\"pt\").to(model.device)\n",
    "inputs = tokenizer.encode(query, return_tensors='pt').to(model.device)  # Tokenize input text\n",
    "outputs = model(inputs)  # Run model\n",
    "attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
    "\n",
    "group_ranges = get_groups(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attn_from_answer_to_disagreement(attention_matrix, group_ranges, layer_head):\n",
    "    layer_idx, head_idx = [int(x) for x in layer_head.split('_')]\n",
    "\n",
    "    disagreement_start, disagreement_end, _ = group_ranges[3]\n",
    "    final_response_start, final_response_end, _ = group_ranges[-1]\n",
    "\n",
    "    slice = attention_matrix[layer_idx][0, head_idx, final_response_start:final_response_end, disagreement_start:disagreement_end]\n",
    "    return torch.sum(slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in range(32):\n",
    "    layer_head = sorted_items[i][0]\n",
    "    score = compute_attn_from_answer_to_disagreement(attention, group_ranges, layer_head)\n",
    "    x.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_items[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz import head_view\n",
    "# 13 4 -> first token of last responses \n",
    "head_view(attention, tokens, layer=13, heads=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sycophancy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
